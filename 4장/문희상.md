# Part 4. 안정적인 AI 서비스 운영하기

## 11. 빠르고 안정적인 AI 서빙 시스템 구성하기

### 서빙이란?
- 학습된 AI 모델을 실제 운영 환경에 배포해 사용자가 실시간으로 요청할 수 있도록 API 형태로 제공하는 과정
- 성능 최적화, API 생성, 확장성 관리, 버전 관리, 모니터링 등을 포함


### 배민의 상황
- AI 플랫폼의 서빙 시스템은 월 약 20억 건의 트래픽을 처리
- 모델을 변경하는 버전 관리, 새로 배포하는 과정에 유실이 없도록 하는 무중단 배포, 문제가 있을 때 빠르게 복구하는 롤백 처리 등이 철저히 이루어져야 한다


## 서빙 컴포넌트
### 벤토ML
- 여러 프레임워크를 지원하며 빠른 개발이 가능한 벤토ML을 활용해 모델 서빙 환경을 구성
- 컨테이너화를 쉽게 지원해 이후 쿠버네티스 배포를 편리
- 전처리/후처리와 같은 비즈니스 로직을 간편하게 추가해 서비스 구성을 빠르게 완성

## CI 이미지 생성 자동화
- 하나의 레포에서 모든 서비스를 관리하는 모노레포 방식으로 관리
- 이미지를 빌드하는 과정에서는 모델을 이미지 내에 넣는 방식을 사용
- Semantic Versioning 방식 이용
- 마이너 버전 변경은 롤링 업데이트
- 메이저 버전 변경은 OASDiff로 현재 서빙되고 있는 API와 새로 생성도리 API 사이에 Breaking Changes 가 있는지 감지할 수 있게 구성
  - 이때는 Blue-Green 배포 사용
 
## CD 서빙 자동화
![IMG_4959](https://github.com/user-attachments/assets/e11de98b-7b7a-462a-9ce4-b2653249aeb3)

## 운영 중 맞이한 문제
### keepalive로 발생한 간헐적 응답 에러
- Keepalive는 연결을 재설정하지 않고도 다수의 요청/응답을 처리할 수 있어 성능이 향상
- 그러나 ALB는 60초, 벤토ML에서는 옵션이 없어 ASGI 서버로 사용되는 Uvicorn의 기본값인 5초로 설정

### 파드와 ALB의 동기화 지연으로 인한 재배포 시 응답 에러
- 파드의 생명주기와 ALB 대상 그룹의 주기가 맞지 않아 동기화가 늦어져 발생하는 문제
![IMG_4960](https://github.com/user-attachments/assets/38a08235-edac-4ebe-b58c-603a4489b7aa)
- Readiness Gate 옵션을 통해 대상 그룹이 ready 상태가 되어야 기존 파드가 삭제되도록 설정
- 다만 파드가 삭제되는 경우에는 여전히 문제 발생 가능
- preStop hook을 통해 파드가 종료되기 전 지연시간 설정을 통해 해결

### 벤토ML 메모리 릭 버그
- 여러 테스트르 통해 벤트ML 자체의 문제라는 것으로 파악
- 이슈를 리포팅해 현재 상황에 대해 공유하고 메인테이너들과 소통을 이어감
- 간단한 경우라면 오픈소스에 기여하고, 난이도가 높다면 적극적이 이슈 리포팅 추천

## 12. 생성형 AI 서비스, 게이트웨이로 쉽게 시작하기

### 개발 배경
#### 생성형 AI 도구들로 인한 변화
- AI/ML 기술적 전문 지식이 없는 일반 사용자들도 손쉽게 AI 기술을 활용할 수 있게 해준다
- 기업들은 자체 모델 개발 또는 사전 훈련된 딥러닝 모델을 새로운 데이터셋이나 특정 작업에 맞게 추가로 학습시키는 파인튜닝 방법에 많은 시간과 비용을 투자하지 않고도, 생성형 AI 도구들을 활용해 빠르게 AI 기반 서비스를 개발하고 출시

#### 대표적인 사례
- 저품질 메뉴 이미지의 개선
- 과도하게 확대 촬영된 메뉴 이미지의 배경 영역을 확장하는 기술을 적용

### 생성형 AI를 잘 활용하려면 무엇이 필요한가
- 자격증명과 프롬프트를 한 곳에 모아 관리할 수 있는 허브 역할이 우선 필요
- 생성형 AI API 호출에 필요한 자격증명들을 서비스 개발자가 게이트웨이에서 손쉰게 추가/수정/삭제하고, 생성형 AI API 별 연동은 게이트웨이 내부에서 처리하도록 했다

### 중복 개발
- 개인 식별 정보
  - 외부 유출 금지
  - 관련 요청은 거부하거나 마스킹 처리한 후 전달
- 로깅
- 제한
  - 할당량 제한과 호출 속도 제한 두가지로 나뉜다

### 비효율적인 배포
- 프폼프트와 같은 리소스 파일 수정을 위해 재배포가 이루어지는 것은 비효율적
- 게이트웨이에서 동적 라우팅과 내부 리소스 관리 기능 구현을 통해 해결
- 유연성 향상, 운영 효율성, 중앙 관리

## AI API 게이트웨이
![IMG_4960](https://github.com/user-attachments/assets/4c5630a1-e0b8-4cfc-91b2-8e5f3e39ae41)
- 게이트웨이는 HTTP 호출과 ML SDK를 통한 호출 두 방식을 지원
- 자격증명 관리
- 템플릿 관리
  - 지속적인 개선과 실험이 필요
- 프록시 생성/관리
  - 서비스에 생성형 AI API를 적용하기 위해 필요한 것은 자격증명, 프롬프트와 적절한 파라미터 값
  - 프록시를 통해 요청 양식 간소화와 엔지니어 도움 없이 데이터 과학자가 즉각 수정/반영 가능






